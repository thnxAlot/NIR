\chapter{Сегментация изображения на детали} %\label{ch2}
	
% не рекомендуется использовать отдельную section <<введение>> после лета 2020 года
%\section{Введение} \label{ch2:intro}

На входе алгоритма поступает массив изображений, каждое из которых содержит в себе рукописный текст. Обрабатывать можно параллельно несколько изображений, если архитектура устройства, на котором будет запущен алгоритм, позволяет выполнять инструкции и команды на нескольких ядрах.

Но не существует алгоритма, который смог бы обработать целиком всю страницу. Такую задачу следует декомпозировать на нескольно подзадач - этапы. И первые из них сперва произвести элементарные единицы текста, которые потом в последствии алгоритм распознавания сможет определить и выдать на выходе цифровой текст.

\section{Первичная обработка изображения}

Прежде чем сегментировать текст на изображении, его нужно сперва обработать, то есть сделать пригодным для удобного использования многими алгоритмами разбиения. Способов реализации для этой задачи существует несколько, но результат должен быть один – черно-белое изображение, где текст выделен определенным цветом, к примеру черным, а фон иным. Кроме этого, удалены шумы и прочие дефекты, хотя второе можно отбрасывать на этапе поиска текста.

Первым делом нужно повысить качество изображения. Чтобы это сделать, в самом начале работы можно убрать излишние шумы и провести сглаживание. Широко применяемый для шумоподавления фильтр Гаусса отлично подойдет и в нашем случае. Если же изображение изначально было размытно, то хорошо было бы повысить его четкость, чтобы далее было проще определять строки.

После нужно привести цветное изображение к черно-белому варианту. Это можно просто сделать, используя известную формулу для каждого пикселя: 
\begin{equation}% лучше не оставлять пропущенную строку (\par) перед окружениями для избежания лишних отсупов в pdf
	\label{eq:Pixel-ch1} % eq - equations, далее название, ch поставлено для избежания дублирования
	C = 0,2989 * R + 0,5870 * G + 0,1140 * B,
\end{equation}
где С – результирующее значение, R, G, B – красная, зеленая и синяя составляющие исходного цвета, каждый параметр в пределах [0; 1]. 

Когда изображение окажется в черно-белом формате, нужно провести пороговую бинаризацию, благодаря которой черный цвет изображения будет соответствовать тексту или «мусору» на данном этапе, а белый фону. То есть уберутся шероховатости, теневые дефекты изображения. Исходя из пиков черного и белого цвета, то есть областей с самым темным цветом и самым светлым цветом можно отбросить все средние значения, округлив их по определенным параметрам, которые предварительно подбираются наиболее оптимально исходя из карты порогов. Это можно осуществить, например, методом Оцу.\cite{otzu} Но, кроме этого, если заранее определить, какая составляющая цветого оттенка преобладает больше в изображении, можно изменить константы в выше приведенной формуле. В таком случае изображение сразу станет наиболее контрастным и пороговая бинаризация обеспечит лучший результат.

После такого рода обработки можно смело составлять компоненты связности и производить отброс уже ненужной информации, как например изображения, пятна или прочие лишние элементы. Это можно сделать, используя нейронные сети, которые будут классифицировать объекты, относящиеся к тексту и нет, однако это потребует сложных операций, которые, в свою очередь, добавят дополнительные нагрузки. Помимо такого способа можно обрабатывать геометрические свойства объектов и среднюю яркость малых участков относительно соседних.

\section{Сегментация строк}

На данном этапе нужно получить отдельные изображения, в каждом из которых будет содержаться строка текста. И чтобы реализовать данную задачу, существует два основных подхода обработки: снизу вверх (bottom-up approach) и сверху вниз (top-down approach).

Идея первого заключается в обработке «самых маленьких» компонент связности, к примеру тех, что образуются при анализе каждого пикселя и его соседних элементов: если пиксель черный, и у него есть соседний элемент, который обладает белым цветом, то мы заключаем его в компонент. Причем соседство смотрится по всем направлениям, то есть все восемь пикселей вокруг текущего. Далее они все связываются, и мы можем получить отдельные слова, буквы. Объединяя последние достигаем уровня строк. Получение крупных объектов идет из объединения более мелких.
 
Идея top-down подхода заключается в противоположной идее, когда сначала идет сегментация на строки, затем сегментация из этих строк на слова, а затем уже, если это требуется, на отдельные элементы, такие как буквы.

Способов получить отдельные строки существует на данный момент несколько, некоторые из них:
\begin{itemize}
	\item Метод горизонтальной проекции. Заключается он в нахождении горизонтального профиля изображения. Сначала считаются суммы пикселей вдоль горизонтального направления. Затем ищутся локальные минимумы у такого профиля. Они же будут соответствовать интервалу между строк. В случае, если изображение строго разделено на два цвета – белый и черный, то суммы в интервалах будут значительно отличаться от тех, что находились на строках. Но такой подход достаточно хорошо анализирует изображение, если текст близко к печатному, когда все строки параллельны и имеют большой интервал между собой, тогда такие суммы будут близки к нулю. Но в общем случае при рукописном тексте интервал может быть минимальным или вовсе строки накладываются друг на друга. Кроме того, он перестает быть эффективным при значительном наклоне текста, так как профиль приобретает более-менее равномерный вид. В таком случае можно использовать модификацию данного метода – локальный горизонтальный профиль. В таком случае применяются дополнительные средства, которые позволяют в изображении даже с градациями серого отметить строки, учитывая их наклон. Но если речь идет о документах, где текст находится в различных местах, то такие подходы становятся менее эффективными. 
	\item Если допустить, что буквы пишутся не слитно, а с определенным интервалом, то существует метод диаграмм Вороного, который позволяет сегментировать текст с использованием bottop-up подхода. Все буквы разделяются между собой на участки, после чего из таких участков можно получить слова, и затем строки. Но, очевидно, что такой способ наиболее часто не применим.\cite{Yosef2009LineSF}
	\item Существует предположение, что человек при письме пишет строки по воображаемым линиям, базовым линиям (based lines), и задача состоит в том, чтобы найти их. Для этого сначала определяются значимые компоненты связности. В них ищутся все локальные экстремумы (минимумы и максимумы), и средняя разница по каждому определяет высоту компонента. После определенных дополнительных операций можно получить направление линии для каждой строки. Но такой метод подразумевает, что строки будут идти прямо, а не извилисто, потому что во втором случае такой метод не сможет аппроксимировать наши получаемые значения для нахождения прямой. Однако такой способ отлично работает и за небольшую трату времени. И его можно улучшить, получая уже не прямую, а кривую при аппроксимации. Однако на это придется потратить ресурсы.\cite{kim}
	
\end{itemize}

\section{Сегментация слов}

Сегментация слов достаточно сложный этап. Входом в алгоритм служит изображение, представляющее строку, полученное на предыдущем этапе разделения строк. В машинном тексте задача не является сложной – интервалы между словами четко определены, поскольку имеют более-менее одинаковую длину, а также существует более четкая грань в разделении слова и самого интервала. В рукописном тексте могут быть удлиненные штрихи, которые не позволяют строго разделять интервал от слова, он получается более размытым. Кроме этого, пробелы между словами не всегда гораздо длиннее, чем пробелы в словах, а расстояние между слов может варьироваться в широких пределах. Квалифицировать данный процесс достаточно тяжело. Далее пойдет речь о двух подходах для реализации данной задачи.

Первый заключается в использовании нейронной сети. В заранее подготовленной строке нужно разобрать все пустоты по двум классам: пробел между слов и пробел в самом слове. Для этого можно использовать многоуровневый персептрон. По сути, такой способ хорошо подходит для поставленной задачи.

Второй способ заключается в использовании геометрических свойствах компонент связности. Можно анализировать расстояния между связными элементами. Причем тут есть различные разновидности того, как это осуществить: можно смотреть длину между двумя крайними точками, что позволит оценивать штрихи, а можно оценивать проекцию расстояния по горизонтали, как длину интервала или брать среднее значение.

При использовании диаграмм Вороного на предыдущем этапе, разделение на слова не составляет трудностей, ибо среди ячеек будут присутствовать явные пробелы, так как в определенных буквенных ячейках будет присутствовать пустота по х, большая, чем в других.

Можно использовать еще один способ, который отлично работает при печатных текстах. Если исходное изображение не было подвергнуто на фазе предварительной обработки пороговой бинаризации, то здесь самое время ее применить. После размыть Гауссовым методом изображение вдоль горизонтального направления. Тогда компоненты букв начнут более сильно пересекаться, что позволит объединить их в одну. Или еще лучше полностью размыть изображение, чтобы слова стали буквально единым целым, а интервалы между ними были бы с наименьшей яркостью. После чего можно повторно применить упрощенную версию пороговой бинаризации и использовать способ горизонтальной проекции, но вдоль вертикального направления. Таким образом, подсчитав суммы пикселей, можно будет найти локальные минимумы, которые будут соответствовать интервалам между слов.\cite{kak}

\section{Выводы} \label{ch2:conclusion}

Важным фактором для определения и разбиения текста на изображении является его предварительная обработка. Если изображение будет содержать повреждения, лишние детали, то это существенно будет усложнять алгоритмы разбиения текста на строки, и далее на слова. Наиболее часто для таких целей используют фильтры Гаусса и пороговой бинаризации, их достаточно, чтобы текст стал контрастным на большинстве типов изображений.

Наиболее предпочтительным способом сегментации все-таки является top-down подход, так как у него больше примеров практических реализации, к ним также прилагаются различные модификации. Выявив значительные преимущества каждого, можно составить свой вариант, который будет преобладать по точности и результативности.

%% Вспомогательные команды - Additional commands
%
%\newpage % принудительное начало с новой страницы, использовать только в конце раздела
%\clearpage % осуществляется пакетом <<placeins>> в пределах секций
%\newpage\leavevmode\thispagestyle{empty}\newpage % 100 % начало новой страницы